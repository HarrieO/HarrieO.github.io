---
title: "Keeping Dataset Biases out of the Simulation: A Debiased Simulator for Reinforcement Learning based Recommender Systems"
authors: "Jin Huang, Harrie Oosterhuis, Maarten de Rijke and Herke van Hoof"
collection: publications
permalink: /publication/2020-recsys
excerpt: "We introduce a debiasing step in a RecSys simulation pipeline, which corrects for the biases present in the logged data before it is used to simulate user behavior. To evaluate the effects of bias on RL4Rec simulations, we propose a novel evaluation approach for simulators that considers the performance of policies optimized with the simulator. Our results reveal that the biases from logged data negatively impact the resulting policies, unless corrected for with our debiasing method."
date: 2020-09-22
venue: 'Proceedings of the Fourteenth ACM Conference on Recommender Systems (RecSys â€™20)'
paperurl: http://harrieo.github.io/files/2020-recsys-simulation.pdf
citation: "J. Huang, H. Oosterhuis, M. de Rijke, and H. van Hoof. &quot;Keeping Dataset Biases out of the Simulation: A Debiased Simulator for Reinforcement Learning based Recommender Systems.&quot; In <i>Fourteenth ACM Conference on Recommender Systems</i>, pp. 190-199. ACM, 2020."
youtube: 
codeurl: https://github.com/BetsyHJ/SOFA
othervideo: http://harrieo.github.io/files/2020-recys-simulation.mp4
---

Reinforcement learning for recommendation (RL4Rec) methods are increasingly receiving attention as an effective way to improve long-term user engagement. However, applying RL4Rec online comes with risks: exploration may lead to periods of detrimental user experience. Moreover, few researchers have access to real-world recommender systems. Simulations have been put forward as a solution where user feedback is simulated based on logged historical user data, thus enabling optimization and evaluation without being run online. While simulators do not risk the user experience and are widely accessible, we identify an important limitation of existing simulation methods. They ignore the interaction biases present in logged user data, and consequently, these biases affect the resulting simulation. As a solution to this issue, we introduce a debiasing step in the simulation pipeline, which corrects for the biases present in the logged data before it is used to simulate user behavior. To evaluate the effects of bias on RL4Rec simulations, we propose a novel evaluation approach for simulators that considers the performance of policies optimized with the simulator. Our results reveal that the biases from logged data negatively impact the resulting policies, unless corrected for with our debiasing method. While our debiasing methods can be applied to any simulator, we make our complete pipeline publicly available as the Simulator for OFfline leArning and evaluation (SOFA): the first simulator that accounts for interaction biases prior to optimization and evaluation.